{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cca016f",
   "metadata": {},
   "source": [
    "In this notebook I am choosing the new runlist for HESS datasets based on Fermi results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1334f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "from gammapy.maps import MapAxis, WcsGeom, Map\n",
    "from gammapy.data import DataStore\n",
    "from gammapy.makers import MapDatasetMaker, SafeMaskMaker, FoVBackgroundMaker\n",
    "from gammapy.modeling.models import (\n",
    "    FoVBackgroundModel,\n",
    "    Models,\n",
    ")\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.datasets import MapDataset\n",
    "from gammapy.irf import Background3D\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea05856",
   "metadata": {},
   "outputs": [],
   "source": [
    "muoneff_flag= True\n",
    "edisp = True\n",
    "\n",
    "hessera='hess1u'\n",
    "name_afterFermi = 'v1'\n",
    "idx = 2 # 0,1,2\n",
    "\n",
    "if hessera == 'hess1':\n",
    "    full_runlist = np.loadtxt(f'runlist_min_{hessera}_{idx}.txt')\n",
    "else:\n",
    "    full_runlist = np.loadtxt(f'runlist_min_{hessera}.txt')\n",
    "\n",
    "if hessera =='hess1u':\n",
    "    muoneff_flag=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e99aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading general parameters\n",
    "with open(\"/home/vault/caph/mppi062h/repositories/HESS_3Dbkg_syserror/general_config.yml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "conf=cfg['conf']\n",
    "repo_path=cfg['repo_path']\n",
    "N_ebins = cfg['N_ebins']\n",
    "zen_bins = cfg['zen_bins']\n",
    "\n",
    "muoneff_path = cfg['muoneff_path']\n",
    "model_str = cfg['model_str']\n",
    "energy_bins = np.logspace(-1, 2, N_ebins+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbdc229",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = f'$FITS_PROD/{hessera}/std_{conf}_fullEnclosure'\n",
    "ds = DataStore.from_dir(basedir, f'hdu-index-bg-latest-fov-radec.fits.gz', f'obs-index-bg-latest-fov-radec.fits.gz')\n",
    "obs_table = ds.obs_table\n",
    "\n",
    "mask = [True if obsid in full_runlist else False for obsid in obs_table['OBS_ID']]\n",
    "obs_table=obs_table[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d384e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = MapAxis.from_edges(energy_bins, unit=\"TeV\", name=\"energy\", interp=\"log\")\n",
    "binsz=cfg['binsz']*u.deg\n",
    "maker = MapDatasetMaker()\n",
    "if edisp:\n",
    "    maker_safe_mask = SafeMaskMaker(methods=['offset-max', 'bkg-peak', 'edisp-bias'], offset_max=cfg['offset_cut']*u.deg) \n",
    "else:\n",
    "    maker_safe_mask = SafeMaskMaker(methods=['offset-max'], offset_max=cfg['offset_cut']*u.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d191f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(runlist, axis, muoneff_flag, name, background_oversampling=1):\n",
    "    observations = ds.get_observations(runlist)\n",
    "    maker = MapDatasetMaker()\n",
    "    geom = WcsGeom.create(skydir=(0,0), binsz=binsz, width=8, frame=\"galactic\", axes=[axis])\n",
    "    stacked = MapDataset.create(geom=geom)\n",
    "\n",
    "    norm_tilt_list = []\n",
    "    for j, obs in enumerate(observations):\n",
    "        zen_bin = np.sum(obs.pointing_zen.value > zen_bins) - 1\n",
    "        \n",
    "        if muoneff_flag:\n",
    "            muoneff_path=f'/home/saturn/caph/sn0533/shared/hess/fits/bgmodel_3d/prod05/std_zeta_fullEnclosure/{hessera}/hess1_hess2/v01c_kaori_mueff'\n",
    "            if obs.obs_info['MUONEFF'] > 0.085:\n",
    "                model_CD = 'B'\n",
    "            elif obs.obs_info['MUONEFF'] >= 0.075:\n",
    "                model_CD = 'D'\n",
    "            else:\n",
    "                model_CD = 'C'\n",
    "\n",
    "            if obs.obs_id >= 100000:\n",
    "                run_number= f'{obs.obs_id}'\n",
    "            else:\n",
    "                run_number= f'0{obs.obs_id}'\n",
    "            filename = f'{muoneff_path}_{model_CD}/hess_bkg_3d_v01c_kaori_mueff_{model_CD}_norebin_fov_radec_{run_number}.fits.gz'\n",
    "            obs.bkg = Background3D.read(filename, hdu='BACKGROUND')\n",
    "        \n",
    "        dataset = stacked.cutout(obs.pointing_radec, width=5)\n",
    "        dataset = maker.run(dataset, obs)\n",
    "        \n",
    "        # this is to set bkg to 0 when it has unreasonable values in the highest energies\n",
    "        spectrum = np.sum((dataset.background).data, axis=(1,2))\n",
    "        for i in range(1, 5):\n",
    "            if spectrum[-1*i] > spectrum[-1*(i+1)]:\n",
    "                dataset.background.data[-1*i] = 0\n",
    "        bkg= np.sum((dataset.background).data, axis=(1,2))\n",
    "        \n",
    "        dataset = maker_safe_mask.run(dataset, obs)\n",
    "        \n",
    "        dataset.mask_fit = Map.from_geom(geom=dataset.counts.geom, data=np.ones_like(dataset.counts.data).astype(bool))   \n",
    "        dataset.mask_fit &= ~dataset.counts.geom.region_mask(f\"galactic;box(0, 0, 4.3, 1.6)\")\n",
    "        dataset.mask_fit &= ~dataset.counts.geom.region_mask(f\"galactic;circle(358.71, -0.64, 0.9)\")\n",
    "        \n",
    "        bkg_model = FoVBackgroundModel(dataset_name=dataset.name)\n",
    "        dataset.models = Models([bkg_model])\n",
    "        dataset.background_model.spectral_model.tilt.frozen = False\n",
    "        Fit().run(datasets=[dataset])\n",
    "                \n",
    "        if dataset.background_model.spectral_model.norm.value > 0:\n",
    "            dataset.background.data[~dataset.mask_safe.data] = 0.0\n",
    "            stacked.stack(dataset)\n",
    "            norm_tilt_list.append([obs.obs_id, dataset.background_model.spectral_model.norm.value, dataset.background_model.spectral_model.tilt.value])\n",
    "        else:\n",
    "            print(f'run: with problem={obs.obs_id}')\n",
    "    np.savetxt(f'norm_tilt_min{name[8:]}.txt', np.asarray(norm_tilt_list))\n",
    "\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383f4833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No HDU found matching: OBS_ID = 137994.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 137995.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 137997.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138024.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138025.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138055.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138089.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138112.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138138.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138139.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147848.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 151790.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 152629.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153116.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153120.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147847.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138087.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 152222.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147810.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147809.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138114.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 137992.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 152226.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153125.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 138086.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 137993.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 140950.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153129.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153029.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147846.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 146970.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153811.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153133.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147808.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 137991.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153792.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147845.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147879.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153031.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147121.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153813.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 146969.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147843.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 153032.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 147805.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "No HDU found matching: OBS_ID = 146898.0, HDU_TYPE = rad_max, HDU_CLASS = None\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n",
      "Missing 'HDUCLAS2' keyword assuming 'BKG'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 48s, sys: 11.9 s, total: 4min\n",
      "Wall time: 4min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "runlist = full_runlist\n",
    "if hessera == 'hess1':\n",
    "    name = f'dataset_min_{hessera}_muoneff{muoneff_flag}_edisp{edisp}_afterFermi{name_afterFermi}_{idx}'\n",
    "else:\n",
    "    name = f'dataset_min_{hessera}_muoneff{muoneff_flag}_edisp{edisp}'\n",
    "    \n",
    "axis = MapAxis.from_edges(np.logspace(-1,2,25), unit=\"TeV\", name=\"energy\", interp=\"log\")\n",
    "\n",
    "stacked = create_dataset(runlist, axis, muoneff_flag, name)\n",
    "stacked.write(f'{name}.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b23b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f4eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83030c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gammapy-0.19]",
   "language": "python",
   "name": "conda-env-gammapy-0.19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
